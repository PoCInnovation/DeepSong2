{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ca99a8",
   "metadata": {},
   "source": [
    "> This Jupyter Notebook contains the second part of the workshop, if you have not done the first one I invite you to do it before starting this one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3f1fe",
   "metadata": {},
   "source": [
    "First of all, I hope you have understood the theoretical part of this workshop. Indeed, the latter will be very useful for this part! If you have any questions about the first part, this is the time to ask the supervisors.\n",
    "\n",
    "You will need to create a modell predicting the garment on a 28 x 28 pixel image. You are free to create the model you want, I advise you to start with the simplest and improve it as you go along.\n",
    "\n",
    "Obviously, I'm not going to let you start without a little help. Below you will find an incomplete code that will allow you to do this workshop. All you have to do is fill in the missing parts marked with comments starting with ###. You will also have to modify the hyper parameters (EPOCH, BATCH_SIZE, LR).\n",
    "\n",
    "We will use the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), which contains standardised clothing images.\n",
    "\n",
    "### It's up to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10dda7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "828b7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        # Convolution layer\n",
    "        self.conv1 = torch.nn.Conv2d(1, 1, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(1, 1, kernel_size=2)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # --------------------------------\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.linear1 = torch.nn.Linear(16, 64)\n",
    "        self.linear2 = torch.nn.Linear(64, 10)\n",
    "        # --------------------------------\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Enter your code here: you can use the functions above as a guide\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear1(x))\n",
    "        ### Don't forget the activation functions\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "209cf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb64a7c",
   "metadata": {},
   "source": [
    "For this exercise, we will use real data provided by FashionMNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dbd9541a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data_set'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[80], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[1;32m      8\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[1;32m      9\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mNormalize((\u001B[38;5;241m0.1307\u001B[39m,), (\u001B[38;5;241m0.3081\u001B[39m,))\n\u001B[1;32m     10\u001B[0m ])\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Load data\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m train_set \u001B[38;5;241m=\u001B[39m \u001B[43mtorchvision\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFashionMNIST\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./data_set\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m test_set \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mFashionMNIST(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data_set\u001B[39m\u001B[38;5;124m\"\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtransform)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Select a batch of data\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:99\u001B[0m, in \u001B[0;36mMNIST.__init__\u001B[0;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[0;32m---> 99\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_exists():\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset not found. You can use download=True to download it\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:179\u001B[0m, in \u001B[0;36mMNIST.download\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_exists():\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 179\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;66;03m# download files\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m filename, md5 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresources:\n",
      "File \u001B[0;32m/usr/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/os.py:225\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 225\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exist_ok \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39misdir(name):\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './data_set'"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "EPOCH = 2\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Convert and normalize input images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load data\n",
    "train_set = torchvision.datasets.FashionMNIST(root=\"./data_set\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.FashionMNIST(root=\"./data_set\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Select a batch of data\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Define label names\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d3dbe41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[81], line 8\u001B[0m\n\u001B[1;32m      4\u001B[0m     plt\u001B[38;5;241m.\u001B[39mimshow(np\u001B[38;5;241m.\u001B[39mtranspose(np_img, (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m)))\n\u001B[1;32m      5\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m----> 8\u001B[0m img_show(\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mtrain_loader\u001B[49m))[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Display the image passed as input to the model\n",
    "def img_show(img):\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "img_show(next(iter(train_loader))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f18b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a loss calculator and optimizer\n",
    "### Define criterion and optimizer\n",
    "loss_fonct = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e205bd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[84], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     13\u001B[0m success \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[43mtrain_loader\u001B[49m):\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;66;03m# Enter your code here: ~ 5 lines of code\u001B[39;00m\n\u001B[1;32m     16\u001B[0m     \n\u001B[1;32m     17\u001B[0m     \n\u001B[1;32m     18\u001B[0m     \n\u001B[1;32m     19\u001B[0m     \n\u001B[1;32m     20\u001B[0m     \n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m###\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(output\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     24\u001B[0m     total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "\n",
    "train_accuracies = np.zeros(EPOCH)\n",
    "test_accuracies = np.zeros(EPOCH)\n",
    "\n",
    "for iteration in range(EPOCH):\n",
    "    average_loss = 0.0\n",
    "\n",
    "    print(\"――――――――――――――――――――――――――――――――――――――――――――――――――\")\n",
    "\n",
    "    # Training\n",
    "    total = 0\n",
    "    success = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        # Enter your code here: ~ 5 lines of code\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        success += (predicted == labels.data).sum()\n",
    "\n",
    "    train_accuracies[iteration] = 100.0 * success / total\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    # Testing\n",
    "    total = 0\n",
    "    success = 0\n",
    "    for inputs, labels in tqdm(test_loader):\n",
    "        output = None\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        success += (predicted == labels.data).sum()\n",
    "    test_accuracies[iteration] = 100.0 * success / total\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    print(\"Epoch %d, train accuracy %d, test accuracy %d\" % (\n",
    "        iteration,\n",
    "        train_accuracies[iteration],\n",
    "        test_accuracies[iteration]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e71084",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "Can you make the model work? Have you managed to create a basic model but don't know how to improve it? This part is for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62c258",
   "metadata": {},
   "source": [
    "1. You process images, have you used convolutions? [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)\n",
    "2. Did you use the pooling operation after your convolution? [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)\n",
    "3. Have you used the dropout to avoid overfitting? [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout)\n",
    "4. Have you tested other activation functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5d2a5",
   "metadata": {},
   "source": [
    "Now that you're proud of your model, don't hesitate to share it with others! Also, feel free to compare your models to see what works well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
