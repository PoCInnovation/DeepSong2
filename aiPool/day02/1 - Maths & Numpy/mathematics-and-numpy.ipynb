{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec86331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import math\n",
    "import numpy as np\n",
    "import workshop_utils as ws\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fbbf105",
   "metadata": {},
   "source": [
    "# Mathematics with Numpy\n",
    "\n",
    "Welcome to day two of the AI pool!\\\n",
    "Now that you have mastered the basics of Python, you will be able to use this language to perform complex mathematical operations.\n",
    "\n",
    "⚠️ Make sure that you have executed the above cell without errors or you will not be able to follow the notebook properly !\n",
    "\n",
    "### It's time to take the plunge 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdd3b8",
   "metadata": {},
   "source": [
    "## 1. Native math vs NumPy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d693a61e",
   "metadata": {},
   "source": [
    "![Numpy logo](./images/numpy.png)\n",
    "\n",
    "First, you may wonder what Numpy is?\n",
    "\n",
    "> NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "\n",
    "🔗 [NumPy](https://numpy.org/)  \n",
    "🔗 [NumPy Reference](https://numpy.org/doc/stable/reference/index.html#reference)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0bd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function displays the two variables passed as parameters whatever their type\n",
    "\"\"\"\n",
    "def display_variables(x, y):\n",
    "    x, y = str(x), str(y)\n",
    "    print(x, '->', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afc2a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = -8\n",
    "y = # use the `fabs` method from math library\n",
    "\n",
    "display_variables(x, y)\n",
    "assert y == 8\n",
    "print('Math library seems to work well with number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6dd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [-8, 10, -3]\n",
    "y = # use `fabs` function from math library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d2072e1",
   "metadata": {},
   "source": [
    "The above code does not work. Indeed the math library can only handle numbers, but we're trying to give it an array of numbers !\n",
    "\n",
    "```\n",
    "TypeError: must be real number, not list\n",
    "```\n",
    "\n",
    "You can comment the line that causes this error so that it doesn't bother you anymore !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f954afb5",
   "metadata": {},
   "source": [
    "That is why, for matrix computations, we use another module called `numpy` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = # use abs function from numpy library\n",
    "\n",
    "display_variables(x, y)\n",
    "assert np.all(y >= 0)\n",
    "print('NumpPy library seems to work well with array')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e7f1e48",
   "metadata": {},
   "source": [
    "NumPy also works very well with numbers, so you can use its methods when dealing with numbers as well !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d0335",
   "metadata": {},
   "source": [
    "## 2. Function implementation with NumPy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72701b43",
   "metadata": {},
   "source": [
    "NumPy not only allows to perform operations between matrices, it also allows to generate data :\n",
    "\n",
    "---\n",
    "\n",
    "> Try to use a numpy method to complete the `get_data` method which is defined below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size = 30):\n",
    "    \"TODO: this function must return a list containing 30 evenly spaced numbers\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc420c0",
   "metadata": {},
   "source": [
    "If you can't figure out which NumPy function to use, you can follow [this link](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e18135c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Try to implement the sigmoid function whose formula is :\n",
    "\n",
    "$$ sigmoid(x) = \\frac{1}{1+e^{-x}} $$\n",
    "\n",
    "🔗 [Sigmoid function on Wikipedia](https://en.wikipedia.org/wiki/Sigmoid_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11508c28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"TODO: implement sigmoid function with NumPy\"\n",
    "    pass\n",
    "\n",
    "assert sigmoid(1) == 0.7310585786300049\n",
    "print('Bravo, the function has been correctly implemented 🚀')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecbe6c2e",
   "metadata": {},
   "source": [
    "> **WARNING** : we are using the `get_data()` method to generate the data which we will store inside x\\\n",
    "> **WARNING** : unless you have already done so, modify your `get_data()` method so that it starts counting at -10 and ends at 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00109737",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_data()\n",
    "ws.display_function(x, sigmoid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "887a579b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> Try to implement the Mean Squared Error function whose formula is\n",
    "\n",
    "$$ MSE(\\hat{y}, y) = \\frac{1}{n} \\sum_{i=0}^{n} (y^{i} - \\hat{y}^{i})^2 $$\n",
    "\n",
    "> This function measures the difference between two sets of data, the larger the result the more different the data are\n",
    "\n",
    "🔗 [Mean squared Error on Wikipedia](https://en.wikipedia.org/wiki/Mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x, y):\n",
    "    if (type(x) == np.ndarray and type(y) == np.ndarray):\n",
    "        assert len(x) == len(y)\n",
    "    \n",
    "    \"TODO: implement loss function with NumPy\"\n",
    "    pass\n",
    "\n",
    "assert mse(10, 12) == 4\n",
    "assert mse(x, x + 3) == 9\n",
    "print('Bravo, the function has been correctly implemented 🚀')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c45b857",
   "metadata": {},
   "source": [
    "Since the functions have been implemented with NumPy, they can be used with both numbers and arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8b66c",
   "metadata": {},
   "source": [
    "## 3. Gradient descent\n",
    "\n",
    "Try to implement the following functions:\n",
    "\n",
    " $$ f(x)=x^{2} $$\n",
    "  \n",
    " $$ g(x)=\n",
    "\\begin{equation*} \\lvert x \\rvert = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            \\frac{2}{3}{(-x)}^2+2x & \\quad x < 0 \\\\\n",
    "            \\frac{1}{2}{x}^2-2x & \\quad x \\geq 0\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "\\end{equation*} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"TODO: implement f\"\n",
    "    pass\n",
    "\n",
    "def g(x):\n",
    "    \"TODO: implement g\"\n",
    "    pass\n",
    "\n",
    "assert f(4) == 16\n",
    "assert g(-3) == 0\n",
    "assert g(2) == -2\n",
    "print('Bravo, the functions has been correctly implemented 🚀')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42c1eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We will use matplotlib to visualize the two functions you have implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_data(100)\n",
    "ws.display_functions(x, f, g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f14cef53",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Try to implement the following functions:\n",
    " * the derivative of $f$\n",
    " * the derivative of $g$\n",
    " \n",
    "> If you don't know how to calculate a derivative, feel free to look it up.\\\n",
    "> However, don't get stuck on it for too long, this isn't a math pool !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c016af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f_dx(x):\n",
    "    pass\n",
    "\n",
    "def g_dx(x):\n",
    "    pass\n",
    "\n",
    "assert f_dx(4) == 8\n",
    "assert g_dx(-3) == -2\n",
    "assert g_dx(3) == 1\n",
    "#ws.display_functions(x, f, g, f_dx, g_dx)\n",
    "print('Bravo, the functions has been correctly implemented 🚀')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b07bec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We will now try to find the values for which a function is at its local minimum. To do this we will use the gradient descent algorithm\n",
    "\n",
    "$$ \\theta_{j+1} = \\theta_j - \\alpha \\times \\frac{\\partial f}{\\partial x} $$\n",
    "\n",
    "2D gradient descent | 3D gradient descent\n",
    "--------------------|--------------------\n",
    "![2D gradient descent](./images/gradient-descent-2d.png) | ![3D gradient descent](./images/gradient-descent-3d.png)\n",
    "\n",
    "🔗 [Gradient descent on Wikipedia](https://en.wikipedia.org/wiki/Gradient_descent)\n",
    "\n",
    "* Initial value: a random initial value where the algorithm is going to start\n",
    "* Epochs: number of iteration the algorithm will perform\n",
    "* Learning rate: a tuning parameter that determines the step size at each iteration\n",
    "* Steps number: number of steps that will be saved for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529edf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "STEPS_NUMBER = 100\n",
    "\n",
    "def gradient_descent(value, derivative, epochs = EPOCHS, lr = LR, steps_number = STEPS_NUMBER): \n",
    "    for epoch in range(epochs):\n",
    "        \"TODO: the value must be modified according to the gradient descent algorithm\"\n",
    "        pass\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_data()\n",
    "start_value = randint(x[0], x[-1])\n",
    "min = gradient_descent(start_value, f_dx)\n",
    "\n",
    "ws.gradient_descent_visualisation(x, f, min)\n",
    "print('Minimum value of the function found for x = %.2f -> y = %.2f' % (min, f(min)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "444d79a1",
   "metadata": {},
   "source": [
    "Don't hesitate to modify the hyper-parameters of the gradient descent, you have to find the right balance between precision and computation cost. \n",
    "\n",
    "⚠️ A bad configuration of one of these parameters can make you miss the optimal result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf305d",
   "metadata": {},
   "source": [
    "## 4. Local minima issue\n",
    "\n",
    "We find the minimum of the function used in the example. However, our algorithm will not be sufficient for all functions.  \n",
    "As the following illustration shows, non-convergent functions can have local minima.\n",
    "\n",
    "![Global minima illustration](./images/global-minima.png)\n",
    "\n",
    "#### 💡 To get past this problem, we will run the algorithm for many function parameters and not just one starting value\n",
    "\n",
    "🔗 [Non-Convex Optimization in Deep Learning](https://medium.com/swlh/non-convex-optimization-in-deep-learning-26fa30a2b2b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_data()\n",
    "min = gradient_descent(x, g_dx)\n",
    "\n",
    "map_xy = ?\n",
    "\n",
    "ws.gradient_descent_visualisation(get_data(), g, min)\n",
    "print('Minimum value of the function found with y = %.2f' % np.min(map_xy(min)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950f694",
   "metadata": {},
   "source": [
    "As you can see, this function has two local minima, one towards $ x=-1.5 $ and the other towards $ x=2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d68595",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 🎉 Congratulations! You have completed the first notebook of the day.  \n",
    "I hope this first part went well and that you didn't get scared by the formulas.\n",
    "\n",
    "⏭️ Now that you have learned the gradient descent algorithm, you can use it to minimize a function and thus improve the results of a machine learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
